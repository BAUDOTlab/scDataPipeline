---
author: "Céline Chevalier and Anaı̈s Baudot"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
    rmdformats::material:
        use_bookdown: true
        thumbnails: false
        df_print: kable
        code_folding: hide
        number_sections: yes
    pdf_document:
        number_sections: yes
        toc: yes
        toc_depth: 3
        keep_tex: no
title: |
    | Step 11: DEA between conditions -- `r DATASET`
---

<!-- Javascript for zooming on figures (adapted from: https://stackoverflow.com/questions/40401680) -->

<!-- Jquery import conflicts with DT::datatable so needs to be commented here -->
<!-- <script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script> -->
<!-- 
<style>
.zoomDiv {
  display: none;  
  position: fixed;
  top: 50%;
  left: 50%;
  z-index: 50;
  transform: translate(-50%, -50%);
  background-color: #FFFFFF;
  box-shadow: 0px 0px 50px #888888;
  width: fit-content;
  max-width: 90%;
  max-height: 90%;
  overflow: auto;
}

.zoomImg {
  width: 150%;
}
</style>

<script type = "text/javascript">
  $(document).ready(function() {
    $("body").prepend("<div class = \"zoomDiv\"><img src = \"\" class = \"zoomImg\"></div>");
    // onClick for all img except the zoomed one and link ones (filter)
    // use "img.zoom" and out.extra = "class = \"zoom\"" in chunk to specify manually which chunk images can be zoomed
    $("img:not(.zoomImg)").filter(":not(a *)").click(function() {
      $(".zoomImg").attr("src", $(this).attr("src"));
      $(".zoomDiv").show();
    })
    // onClick function for hiding div
    $("img.zoomImg").click(function() {
      $(".zoomDiv").hide();
    })
  })
</script> -->


```{r setup, include = FALSE}
options(knitr.purl.inline = TRUE)
knitr::opts_chunk$set(
  # code evaluation
  eval = TRUE,

  # text output
  echo = TRUE,
  results = "hold",
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  strip.white = TRUE,

  # code decoration
  tidy.opts = list(width.cutoff = 90),
  comment = "",
  attr.output = ".numberLines",

  # plots
  fig.path = paste0(PATH_OUT_FIG, "/06_annotDEAviz_scenario_", scenario, "_"),
  fig.show = "asis",         # tuned to "hold" in multiple plots chunk
  dev = c("png", "pdf"),
  out.width = "50%",
  fig.width = 12,
  fig.height = 12,
  fig.align = "center"   # should be tuned to default in multiple plots chunk
)
```

```{r load-libraries, include = FALSE}
library(Seurat)
library(ggplot2)
library(DElegate)
library(ggrepel)
library(DT)
library(dplyr)
library(knitr)
library(fgsea)
library(msigdbr)
library(data.table)

source("./plotting_functions.R", local = TRUE)
source("./data_management.R", local = TRUE)
source("./checkDirHierarchy.R", local = TRUE)
```

```{r dir-managment, include=FALSE}
# PATHS
PATH_CLUSTER_TABLE <- paste0(PATH_ROOT, "/08_combineData/clustering_", DATASET, "_scenario.", scenario, "_meth.", clust_meth, "_res.", clust_res, ".csv")
PATH_RDS_FILE <- paste0(PATH_RDS_OBJECTS, "/07_preprocessed_", DATASET, "_scenario.", scenario, ".rds")
PATH_OUT_ANALYSIS <- file.path(PATH_ROOT, "09_DEG_analysis")
if (!dir.exists(PATH_OUT_ANALYSIS)) { dir.create(PATH_OUT_ANALYSIS) }

# check file existence
checkPath(PATH_CLUSTER_TABLE)
checkPath(PATH_RDS_FILE)
```


```{r load-data, include=FALSE}
# LOAD DATA
fltd <- readRDS(PATH_RDS_FILE)

# LOAD CLUSTERING RESULTS
clusters <- read.table(PATH_CLUSTER_TABLE, header = TRUE, sep = ",", row.names = "cellIDs")
clustOfInterest <- grep(paste0(DefaultAssay(fltd), "_snn_res.", clust_res), names(clusters), value = TRUE)
fltd@meta.data <- merge(fltd@meta.data, clusters[clustOfInterest], by = 'row.names')
fltd@meta.data <- tibble::column_to_rownames(fltd@meta.data, "Row.names")
```

# Differential Gene Expression by cluster {.tabset .tabset-pills .tabset-fade}

```{r, echo=FALSE,include = FALSE}
# You need this code to conduct the magic dependences attaching...
DT::datatable(matrix())
```

```{r perform-deg, results='asis', out.width='100%'}
perform_deg <- function(clust) {
    cat(paste0("## Cluster ", clust, "\n"))
    cells <- which(fltd@meta.data[clustOfInterest] == clust)
    cluster_data <- fltd[, cells]
    Idents(cluster_data) <- "orig.ident"

    # For DESeq2 to work properly, the cluster must be big enough to have cells from both conditions in a sufficient amount, as they
    # will be split in 3 subgroups. 30 is a very lax threshold, and results from clusters barely passing the check may not be trustworthy
    if (length(table(cluster_data$orig.ident)) > 1 & as.integer(table(cluster_data$orig.ident)[1]) >= 30 & as.integer(table(cluster_data$orig.ident)[2]) >= 30) {
        de_results <- findDE(object = cluster_data, method = "deseq")
        de_results <- de_results[complete.cases(de_results[, 3:7]), ]
    
        top_DE <- filter(de_results, log_fc != 0) %>%
            group_by(sign(log_fc)) %>%
            slice_head(n = 5)
        p = ggplot(de_results, aes(log_fc, -log10(padj))) +
            geom_point(shape = 16, alpha = 0.2) +
            geom_point(data = top_DE, shape = 16, size = 2, color = 'deeppink') +
            geom_text_repel(data = top_DE, aes(label = feature)) +
            ggtitle(paste0(levels(de_results$group1), " vs ", levels(de_results$group2), " for cluster ", clust))

        print(p)
    
        print(datatable(de_results[c(1:201),], rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX=T)))
    
        invisible(write.table(de_results, file =file.path(PATH_OUT_ANALYSIS, paste0("cluster_", clust, "_DEG_", levels(de_results$group1), "_vs_", levels(de_results$group2), ".csv")), col.names = TRUE, row.names = FALSE, sep = ","))

    } else if (length(table(cluster_data$orig.ident)) > 1 & (as.integer(table(cluster_data$orig.ident)[1]) < 30 | as.integer(table(cluster_data$orig.ident)[2]) < 30)) {
        cat(paste0("Too few cells (< 30) in at least one group to perform cell aggregates: cluster ", clust))
        warning(paste0("Too few cells (< 30) in at least one group to perform cell aggregates: cluster ", clust))
    } else {
        cat(paste0("Did not find two or more group levels: cluster ", clust))
        warning(paste0("Did not find two or more group levels: cluster ", clust))
    }

    cat(" \n \n")
}

htmltools::tagList(invisible(mapply(perform_deg, sort(unique(fltd@meta.data[,clustOfInterest])), SIMPLIFY = FALSE)))
```


# Gene set enrichment analysis {.tabset .tabset-pills .tabset-fade}

To perform gene set enrichment analysis fgsea package is used. This package allows to quickly and accurately calculate arbitrarily low GSEA --values
for a collection of gene sets. P-value estimation is based on an adaptive multi-level split Monte-Carlo scheme. See the preprint for algorithmic details.

<a href="https://www.biorxiv.org/content/10.1101/060012v3">Preprint available here.</a>


Threshold of padj < 0.001 is used to filter the pathways.

```{r perform_fgsea, include = FALSE}

file_names <- list.files(path = PATH_OUT_ANALYSIS, pattern = "^cluster_(\\d+)_DEG_.*\\.csv$", full.names = TRUE)

# Define the path to the folder containing the input files
input_folder <- PATH_OUT_ANALYSIS

# Create the output parent folder if it doesn't exist
output_parent_folder <- file.path(PATH_ROOT, "10_fgsea_analysis")
if (!dir.exists(output_parent_folder)) { dir.create(output_parent_folder) }

# Define databases and corresponding subfolders
databases <- c("Reactome", "KEGG", "GOBP", "GOCC")

# Function to perform FGSEA analysis
perform_fgsea_analysis <- function(csv_paths, database) {
  # Reading dea results
  deseq2Results <- read.csv(csv_paths, header = TRUE)

  ## Ranking vector
  rankings <- sign(deseq2Results$log_fc) * (-log10(deseq2Results$pvalue))
  names(rankings) <- deseq2Results$feature

  # Adjust rankings to avoid inf values
  max_ranking <- max(rankings[is.finite(rankings)])
  min_ranking <- min(rankings[is.finite(rankings)])
  rankings <- replace(rankings, rankings > max_ranking, max_ranking * 10)
  rankings <- replace(rankings, rankings < min_ranking, min_ranking * 10)
  rankings <- sort(rankings, decreasing = TRUE)

  # Iterate through databases
  for (db in databases) {
    output_folder <- file.path(output_parent_folder, db)
    if (!dir.exists(output_folder)) { dir.create(output_folder) }

    ### Run FGSEA ###
    msigdbr_species()
    msigdbr_collections()
    
    if (db == "Reactome") {
      gene_sets = msigdbr(
        species = "Mus musculus",
        category = "C2",
        subcategory = "CP:REACTOME"
      )
    } else if (db == "KEGG") {
      gene_sets = msigdbr(
        species = "Mus musculus",
        category = "C2",
        subcategory = "CP:KEGG"
      )
    } else if (db == "GOBP") {
      gene_sets = msigdbr(
        species = "Mus musculus",
        category = "C5",
        subcategory = "GO:BP"
      )
    } else if (db == "GOCC") {
      gene_sets = msigdbr(
        species = "Mus musculus",
        category = "C5",
        subcategory = "GO:CC"
      )
    }

    ## remove duplicates and change to a list
    gene_sets = gene_sets %>% 
    dplyr::distinct(gs_name, ensembl_gene) %>% 
    as.data.frame()
    gene_sets = split(x = gene_sets$ensembl_gene, f = gene_sets$gs_name)

    # Run fgsea
    general_seed <- 17
    set.seed(general_seed)

    fgseaRes <- fgsea(
      pathways = gene_sets,
      stats = rankings,
      minSize = 15,
      maxSize = 500
    )

    ## Results table
    fgseaRes <- fgseaRes[fgseaRes$padj < 0.01 & !is.na(fgseaRes$padj), ]

    # Save results to output folder
    output_file <- file.path(output_folder, paste0("fgseaRes_", tools::file_path_sans_ext(basename(csv_paths)), "_", db, ".csv"))
    fwrite(fgseaRes, file = output_file, sep = "\t", sep2 = c("", " ", ""))
  }
}

# Apply the analysis to each file
for (csv_paths in file_names) {
  perform_fgsea_analysis(csv_paths)
}
```

```{r metadata, echo=FALSE, child="61_show_metadata.Rmd"}
```