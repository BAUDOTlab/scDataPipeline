---
author: "Céline Chevalier and Anaı̈s Baudot"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
    html_document:
        theme:
            bootswatch: yeti
        toc: yes
        toc_float:
          collapsed: false
          smooth_scroll: true
        number_sections: yes
        df_print: kable
        code_folding: hide
    pdf_document:
        number_sections: yes
        toc: yes
        toc_depth: 3
        keep_tex: no
# title: |
#   | Doublets removal
#   | Step {{STEP_ID}}
---

<!-- Javascript for zooming on figures (adapted from: https://stackoverflow.com/questions/40401680) -->

<!-- Jquery import conflicts with DT::datatable so needs to be commented here -->
<!-- <script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script> -->

<style>
.zoomDiv {
  display: none;
  position: fixed;
  top: 50%;
  left: 50%;
  z-index: 50;
  transform: translate(-50%, -50%);
  background-color: #FFFFFF;
  box-shadow: 0px 0px 50px #888888;
  width: fit-content;
  max-width: 90%;
  max-height: 90%;
  overflow: auto;
}

.zoomImg {
  width: 150%;
}
</style>

<script type = "text/javascript">
  $(document).ready(function() {
    $("body").prepend("<div class = \"zoomDiv\"><img src = \"\" class = \"zoomImg\"></div>");
    // onClick for all img except the zoomed one and link ones (filter)
    // use "img.zoom" and out.extra = "class = \"zoom\"" in chunk to specify manually which chunk images can be zoomed
    $("img:not(.zoomImg)").filter(":not(a *)").click(function() {
      $(".zoomImg").attr("src", $(this).attr("src"));
      $(".zoomDiv").show();
    })
    // onClick function for hiding div
    $("img.zoomImg").click(function() {
      $(".zoomDiv").hide();
    })
  })
</script>


```{r setup04-1, include = FALSE}
options(knitr.purl.inline = TRUE)
knitr::opts_chunk$set(
  # code evaluation
  eval = TRUE,

  # text output
  echo = TRUE,
  results = "hold",
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  strip.white = TRUE,

  # code decoration
  tidy.opts = list(width.cutoff = 90),
  comment = "",
  attr.output = ".numberLines",

  # plots
  fig.path = paste0(PATH_OUT_FIG, "/08_combineData_"),
  fig.show = "asis",         # tuned to "hold" in multiple plots chunk
  dev = c("png", "pdf"),
  out.width = "50%",
  fig.width = 12,
  fig.height = 12,
  fig.align = "center"   # should be tuned to default in multiple plots chunk
)
```

```{r load_lib}
library(Seurat)
library(ggplot2)

source("./plotting_functions.R")
source("./data_management.R")
```

```{r load-colors, include = FALSE}
# Create color vectors
colors.table <- read.csv(file.path(PATH_ATLAS, "colorsSheet.csv"), header=T, comment.char="", as.is=T)
colors.celltype <- setNames(colors.table$celltype_color[!is.na(colors.table$celltype)], colors.table$celltype[!is.na(colors.table$celltype)])
colors.stage <- setNames(colors.table$development_stage_color[!is.na(colors.table$development_stage)], colors.table$development_stage[!is.na(colors.table$development_stage)])
```

```{r variableDef1, include=FALSE}
# Split comma separated input files into a list
PATH_OUT_ANALYSIS <- file.path(PATH_ROOT, "08_combineData")
if (!dir.exists(PATH_OUT_ANALYSIS)) { dir.create(PATH_OUT_ANALYSIS) }
```

# Load the data

All integration part removed from this report. Take the code from 06.1_combineData_pipeline.Rmd.
```{r load-data, include=FALSE}
# Load data
data_load <- function(DATASET_NAME) {
    # PATHS
    PATH_RDS_FILE <- paste0(PATH_RDS_OBJECTS, "/05_preprocessed_", DATASET_NAME, "_scenario.", scenario, ".rds")
    # PATH_CLUSTER_TABLE <- paste0(PATH_ROOT, "/06_process/clustering_", DATASET, "_scenario.", scenario, "_meth.", clust_meth, "_res.", clust_res, ".csv")
    
    data <- readRDS(PATH_RDS_FILE)
    
    if(scenario != 1){ # scale.data is empty in scenario 1, so we use it only for scenarios 2 and 3
      data.use = GetAssayData(data, slot="scale.data")
      data = SetAssayData(data, slot="data", new.data=data.use)
    }
    
    return(data)
}

SO.list <- lapply(input_datasets, data_load)
names(SO.list) <- input_datasets
```



```{r integrate-sep-data, eval=combine_meth!="merge", echo=combine_meth!="merge", results='asis'}
cat("
# Integrate the data
")

set.seed(general_seed)

if (combine_meth == "blkS"){
    features <- SelectIntegrationFeatures(object.list = SO.list)
    anchors <- FindIntegrationAnchors(object.list = SO.list, anchor.features = features)
    SO <- IntegrateData(anchorset = anchors)
    
} else if (combine_meth == "seqS"){
    SO <- SO.list[[1]]
    names(SO.list) <- 
    for (a_day in names(SO.list)[2:length(SO.list)]){
        integ.list <- list(SO, SO.list[[a_day]])
        features <- SelectIntegrationFeatures(integ.list)
        anchors <- FindIntegrationAnchors(object.list = integ.list,
                                          anchor.features = features)
        SO <- IntegrateData(anchorset = anchors)
    } 
}

rm(SO.list)
invisible(gc())
```


```{r merge-sep-data, eval=combine_meth=="merge", echo=combine_meth=="merge"}
cat("
# Merge the data
")

SO <- merge(x = SO.list[[1]], y = SO.list[2:length(SO.list)], merge.data = T)
SO

rm(SO.list)
invisible(gc())
```


SHOW THE TABLE OF SO$ORIG.IDENT TO CHECK THE NUMBER OF CELLS FROM EACH DATASET


```{r save2}
saveRDS(SO, file=file.path(PATH_RDS_OBJECTS, paste0("06_combine_", DATASET, "_scenario.", scenario, "_method.", combine_meth, ".rds")))
invisible(gc())
```




<!-- This code chunk will extract all code blocks from `example.Rmd` and write
them to a temporary file, preserving chunk options. It will then read them and
make those chunks avaliable in the current R environment when the presentation
is knitted. -->

```{r include, eval=FALSE, echo=FALSE, include = FALSE}
SO <- ScaleData(SO, verbose = FALSE)
SO.list <- list(SO)
names(SO.list) <- DATASET
```


```{r include2, eval=FALSE, include = FALSE}
tmp_script <- tempfile()
knitr::purl("02_process_pipeline.Rmd", output=tmp_script, quiet = TRUE)
knitr::read_chunk(tmp_script)
#' Run a previously loaded chunk interactively
#'
#' Takes labeled code loaded with load_chunk and runs it in the /global/ envir (unless otherwise specified)
#'
#' @param chunkName The name of the chunk as a character string
#' @param envir The environment in which the chunk is to be evaluated 
run_chunk <- function(chunkName, envir=.GlobalEnv) {
    chunkName <- unlist(lapply(as.list(substitute(.(chunkName)))[-1], as.character))
    # eval(parse(text=knitr:::knit_code$get(chunkName)), envir=envir)
    eval(parse(text=knitr:::knit_code$get(chunkName)), envir=envir)
}
```

<!-- # Preprocessing workflow -->

```{r preprocess-12, message=TRUE, echo=FALSE, results='asis', eval=FALSE}
run_chunk("preprocess-1", envir = environment())
```

```{r clustering_02process2, echo=FALSE, results='asis', eval=FALSE}
run_chunk("clustering_02process", envir = environment())
```

# Visualization

```{r dimplot-cluster-fltd2, fig.align='default', echo=FALSE, results='asis', eval=FALSE}
run_chunk("dimplot-cluster-fltd}", envir = environment())
```

```{r save4-12, eval=FALSE, echo=FALSE, results='asis'}
run_chunk("save4-1", envir = environment())
```

# SessionInfo

```{r sessionInfo}
sessionInfo()
```